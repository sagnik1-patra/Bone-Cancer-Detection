{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2560c624-e473-4915-a903-c104fabf0c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Total images: 50 | Normal=25 | Cancer=25\n",
      "[INFO] Classes: ['Cancer', 'Normal']\n",
      "[SPLIT] train=40  val=5  test=5\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"BoneCancerCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 224, 224, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 112, 112, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 56, 56, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 28, 28, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 423361 (1.61 MB)\n",
      "Trainable params: 422401 (1.61 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 4s 505ms/step - loss: 0.7607 - accuracy: 0.4250 - val_loss: 0.6960 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 273ms/step - loss: 0.6800 - accuracy: 0.5500 - val_loss: 0.7084 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 1s 271ms/step - loss: 0.6226 - accuracy: 0.6750 - val_loss: 0.7262 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.5219 - accuracy: 0.6750 - val_loss: 0.7456 - val_accuracy: 0.4000 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.5619 - accuracy: 0.7000 - val_loss: 0.7732 - val_accuracy: 0.4000 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.4855 - accuracy: 0.7750 - val_loss: 0.8080 - val_accuracy: 0.4000 - lr: 2.5000e-04\n",
      "\n",
      "[DONE] Artifacts in: C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\n",
      " - model_h5 : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\bone_cancer_cnn.h5\n",
      " - label_encoder_pkl : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\label_encoder.pkl\n",
      " - history_json : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\history.json\n",
      " - history_csv : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\history.csv\n",
      " - metrics_json : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\metrics.json\n",
      " - classification_report_txt : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\classification_report.txt\n",
      " - accuracy_curve_png : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\accuracy_curve.png\n",
      " - loss_curve_png : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\loss_curve.png\n",
      " - confusion_matrix_png : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\confusion_matrix.png\n",
      " - roc_curve_png : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\roc_curve.png\n",
      " - test_predictions_csv : C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\artifacts\\test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json, yaml, random, pickle, sys, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------ Config & Paths ------------------\n",
    "BASE_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\")\n",
    "DATA_DIRS = {\n",
    "    \"Normal\": Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\archive\\Research dataset\\Normal\"),\n",
    "    \"Cancer\": Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Bone Cancer Detection\\archive\\Research dataset\\Cancer\"),\n",
    "}\n",
    "ART = BASE_DIR / \"artifacts\"\n",
    "ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    \"seed\": 42,\n",
    "    \"image_size\": 224,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 20,\n",
    "    \"val_split\": 0.1,      # from remaining after test split\n",
    "    \"test_split\": 0.1,\n",
    "    \"augment\": True,\n",
    "    \"optimizer\": {\"name\": \"adam\", \"lr\": 1e-3},\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"note\": \"Binary CNN classifier for Normal vs Cancer bone images.\",\n",
    "}\n",
    "\n",
    "random.seed(CFG[\"seed\"])\n",
    "np.random.seed(CFG[\"seed\"])\n",
    "tf.random.set_seed(CFG[\"seed\"])\n",
    "\n",
    "# ------------------ Helpers ------------------\n",
    "ALLOWED = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def list_images(folder: Path):\n",
    "    if not folder.exists(): return []\n",
    "    return [p for p in folder.rglob(\"*\") if p.suffix.lower() in ALLOWED]\n",
    "\n",
    "def to_py(obj):\n",
    "    \"\"\"Make objects JSON serializable.\"\"\"\n",
    "    import numpy as _np\n",
    "    try:\n",
    "        import tensorflow as _tf\n",
    "    except Exception:\n",
    "        _tf = None\n",
    "    if isinstance(obj, dict): return {k: to_py(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)): return [to_py(v) for v in obj]\n",
    "    if isinstance(obj, _np.generic): return obj.item()\n",
    "    if isinstance(obj, _np.ndarray): return obj.tolist()\n",
    "    if _tf is not None and isinstance(obj, _tf.Tensor): return obj.numpy().tolist()\n",
    "    return obj\n",
    "\n",
    "# ------------------ Scan dataset ------------------\n",
    "records = []\n",
    "for label, d in DATA_DIRS.items():\n",
    "    for p in list_images(d):\n",
    "        records.append({\"path\": str(p), \"label\": label})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "assert len(df) > 0, \"No images found. Check your dataset paths.\"\n",
    "df = df.sample(frac=1.0, random_state=CFG[\"seed\"]).reset_index(drop=True)\n",
    "print(f\"[INFO] Total images: {len(df)} | Normal={sum(df.label=='Normal')} | Cancer={sum(df.label=='Cancer')}\")\n",
    "\n",
    "# ------------------ Encode labels ------------------\n",
    "le = LabelEncoder()\n",
    "df[\"label_id\"] = le.fit_transform(df[\"label\"])  # Normal->0, Cancer->1 (order depends on alphabet)\n",
    "with open(ART / \"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "print(\"[INFO] Classes:\", list(le.classes_))\n",
    "\n",
    "# ------------------ Split ------------------\n",
    "df_trainval, df_test = train_test_split(\n",
    "    df, test_size=CFG[\"test_split\"], stratify=df[\"label_id\"], random_state=CFG[\"seed\"]\n",
    ")\n",
    "df_train, df_val = train_test_split(\n",
    "    df_trainval, test_size=CFG[\"val_split\"], stratify=df_trainval[\"label_id\"], random_state=CFG[\"seed\"]\n",
    ")\n",
    "print(f\"[SPLIT] train={len(df_train)}  val={len(df_val)}  test={len(df_test)}\")\n",
    "\n",
    "# ------------------ tf.data pipeline ------------------\n",
    "IMG_SIZE = CFG[\"image_size\"]\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def _read_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img\n",
    "\n",
    "def _augment(img):\n",
    "    # light augmentations suited for X-rays\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.05)\n",
    "    img = tf.image.random_contrast(img, 0.95, 1.05)\n",
    "    return img\n",
    "\n",
    "def _parse(path, label, training=False):\n",
    "    img = _read_image(path)\n",
    "    if training and CFG[\"augment\"]:\n",
    "        img = _augment(img)\n",
    "    return img, tf.cast(label, tf.float32)\n",
    "\n",
    "def make_ds(df_split: pd.DataFrame, training=False, batch_size=8):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df_split[\"path\"].values, df_split[\"label_id\"].values))\n",
    "    ds = ds.map(lambda p, y: _parse(p, y, training=training), num_parallel_calls=AUTO)\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(4096, len(df_split)), seed=CFG[\"seed\"], reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(df_train, training=True,  batch_size=CFG[\"batch_size\"])\n",
    "val_ds   = make_ds(df_val,   training=False, batch_size=CFG[\"batch_size\"])\n",
    "test_ds  = make_ds(df_test,  training=False, batch_size=CFG[\"batch_size\"])\n",
    "\n",
    "# ------------------ Model (small CNN; no external weights needed) ------------------\n",
    "def build_model(input_shape=(224,224,3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # binary\n",
    "    return models.Model(inputs, outputs, name=\"BoneCancerCNN\")\n",
    "\n",
    "model = build_model((IMG_SIZE, IMG_SIZE, 3))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=CFG[\"optimizer\"][\"lr\"])\n",
    "model.compile(optimizer=opt, loss=CFG[\"loss\"], metrics=CFG[\"metrics\"])\n",
    "model.summary()\n",
    "\n",
    "# ------------------ Callbacks & Train ------------------\n",
    "ckpt_path = ART / \"bone_cancer_cnn.h5\"\n",
    "cbs = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, mode=\"max\", restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(str(ckpt_path), monitor=\"val_accuracy\", mode=\"max\", save_best_only=True),\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=CFG[\"epochs\"],\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open(ART / \"history.json\", \"w\") as f:\n",
    "    json.dump(to_py(hist.history), f, indent=2)\n",
    "pd.DataFrame(hist.history).to_csv(ART / \"history.csv\", index=False)\n",
    "\n",
    "# Ensure best model saved\n",
    "model.save(ckpt_path)\n",
    "\n",
    "# ------------------ Evaluation & Reports ------------------\n",
    "# collect predictions on test set\n",
    "y_true, y_prob, file_paths = [], [], []\n",
    "for batch, (imgs, labels) in enumerate(test_ds):\n",
    "    probs = model.predict(imgs, verbose=0).ravel()\n",
    "    y_prob.extend(probs.tolist())\n",
    "    y_true.extend(labels.numpy().astype(int).tolist())\n",
    "\n",
    "# threshold 0.5\n",
    "y_pred = (np.array(y_prob) >= 0.5).astype(int)\n",
    "\n",
    "# Basic metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "except ValueError:\n",
    "    auc = float(\"nan\")\n",
    "\n",
    "metrics = {\n",
    "    \"datetime\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"image_size\": IMG_SIZE,\n",
    "    \"splits\": {\"train\": int(len(df_train)), \"val\": int(len(df_val)), \"test\": int(len(df_test))},\n",
    "    \"test\": {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc},\n",
    "    \"classes\": list(le.classes_),\n",
    "}\n",
    "with open(ART / \"metrics.json\", \"w\") as f:\n",
    "    json.dump(to_py(metrics), f, indent=2)\n",
    "\n",
    "# Confusion Matrix & Classification Report\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "report = classification_report(y_true, y_pred, target_names=list(le.classes_), digits=4)\n",
    "with open(ART / \"classification_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Plot curves (matplotlib only)\n",
    "def save_curves():\n",
    "    with open(ART / \"history.json\", \"r\") as f:\n",
    "        H = json.load(f)\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    if \"accuracy\" in H: plt.plot(H[\"accuracy\"], marker=\"o\", label=\"Train Acc\")\n",
    "    if \"val_accuracy\" in H: plt.plot(H[\"val_accuracy\"], marker=\"s\", label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy Curve\"); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(ART / \"accuracy_curve.png\", dpi=220); plt.close()\n",
    "\n",
    "    # Loss\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    if \"loss\" in H: plt.plot(H[\"loss\"], marker=\"o\", label=\"Train Loss\")\n",
    "    if \"val_loss\" in H: plt.plot(H[\"val_loss\"], marker=\"s\", label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curve\"); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(ART / \"loss_curve.png\", dpi=220); plt.close()\n",
    "\n",
    "save_curves()\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "def save_cm(cm, class_names):\n",
    "    plt.figure(figsize=(5.6,4.5))\n",
    "    im = plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ART / \"confusion_matrix.png\", dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "save_cm(cm, list(le.classes_))\n",
    "\n",
    "# ROC Curve (if both classes present)\n",
    "def save_roc(y_true, y_prob):\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        plt.figure(figsize=(5.6,4.5))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC={auc:.4f}\")\n",
    "        plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "        plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(ART / \"roc_curve.png\", dpi=220)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "save_roc(y_true, y_prob)\n",
    "\n",
    "# Save per-image predictions CSV (path, true, pred, prob)\n",
    "# (We reconstruct file order by iterating test df with the same batching again to capture file paths)\n",
    "test_paths, test_labels = [], []\n",
    "for p, y in zip(df_test[\"path\"].values, df_test[\"label_id\"].values):\n",
    "    test_paths.append(p); test_labels.append(y)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"path\": test_paths,\n",
    "    \"true_label\": [le.classes_[i] for i in test_labels],\n",
    "    \"pred_label\": [le.classes_[i] for i in y_pred],\n",
    "    \"pred_prob_cancer\": y_prob,  # probability of class '1' (whichever class got encoded as 1)\n",
    "})\n",
    "pred_df.to_csv(ART / \"test_predictions.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ------------------ Save config ------------------\n",
    "CFG_SAVE = {\n",
    "    **CFG,\n",
    "    \"paths\": {k: str(v) for k, v in DATA_DIRS.items()},\n",
    "    \"artifacts\": {\n",
    "        \"model_h5\": str(ckpt_path),\n",
    "        \"label_encoder_pkl\": str(ART / \"label_encoder.pkl\"),\n",
    "        \"history_json\": str(ART / \"history.json\"),\n",
    "        \"history_csv\": str(ART / \"history.csv\"),\n",
    "        \"metrics_json\": str(ART / \"metrics.json\"),\n",
    "        \"classification_report_txt\": str(ART / \"classification_report.txt\"),\n",
    "        \"accuracy_curve_png\": str(ART / \"accuracy_curve.png\"),\n",
    "        \"loss_curve_png\": str(ART / \"loss_curve.png\"),\n",
    "        \"confusion_matrix_png\": str(ART / \"confusion_matrix.png\"),\n",
    "        \"roc_curve_png\": str(ART / \"roc_curve.png\"),\n",
    "        \"test_predictions_csv\": str(ART / \"test_predictions.csv\"),\n",
    "    },\n",
    "    \"classes\": list(le.classes_),\n",
    "}\n",
    "with open(ART / \"config.yaml\", \"w\") as f:\n",
    "    yaml.safe_dump(to_py(CFG_SAVE), f, sort_keys=False)\n",
    "\n",
    "print(\"\\n[DONE] Artifacts in:\", ART)\n",
    "for k, v in CFG_SAVE[\"artifacts\"].items():\n",
    "    print(\" -\", k, \":\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4fa71-5b05-411d-9e16-bbf9c188b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
